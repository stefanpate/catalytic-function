{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalytic_function.model import MPNNDimRed, TwoChannelFFN, TwoChannelLinear\n",
    "from catalytic_function.nn import BondMessagePassing, LinDimRed\n",
    "from chemprop.nn import MeanAggregation\n",
    "from catalytic_function.nn import DotSig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h_encoder = 20\n",
    "pred_head = DotSig(input_dim=d_h_encoder * 2)\n",
    "mp = BondMessagePassing(d_v=67, d_e=7, d_h=d_h_encoder, depth=1)\n",
    "agg = MeanAggregation()\n",
    "embed_dim = 1280\n",
    "n_epochs = 4\n",
    "\n",
    "model = MPNNDimRed(\n",
    "        reduce_X_d=LinDimRed(d_in=embed_dim, d_out=d_h_encoder),\n",
    "        message_passing=mp,\n",
    "        agg=agg,\n",
    "        predictor=pred_head,\n",
    "    )\n",
    "\n",
    "res_dir = \"/projects/p30041/spn1560/hiec/artifacts/model_evals/gnn\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "chkpt_idx = 8\n",
    "split_idx = 0\n",
    "n_splits = 5\n",
    "chkpt_dir = f\"{res_dir}/{chkpt_idx}_hp_idx_split_{split_idx+1}_of_{n_splits}/version_0/checkpoints\"\n",
    "chkpt_file = os.listdir(chkpt_dir)[0]\n",
    "chkpt_path = f\"{chkpt_dir}/{chkpt_file}\"\n",
    "chkpt = torch.load(chkpt_path, map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "chkpt = torch.load('/projects/p30041/spn1560/hiec/artifacts/model_evals/gnn/88_hp_idx_split_5_of_5/version_0/checkpoints/epoch=18-step=26790.ckpt')\n",
    "chkpt['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    enable_checkpointing=False,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=0, # number of epochs to train for\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mfit(\n\u001B[1;32m      2\u001B[0m     model,\n\u001B[0;32m----> 3\u001B[0m     torch\u001B[38;5;241m.\u001B[39mDataLoader(),\n\u001B[1;32m      4\u001B[0m )\n",
      "File \u001B[0;32m~/.conda/envs/hiec/lib/python3.11/site-packages/torch/__init__.py:1833\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m   1830\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mimportlib\u001B[39;00m\n\u001B[1;32m   1831\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m-> 1833\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodule \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'torch' has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    torch.DataLoader(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# - or -\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 1,\n",
       " 'global_step': 2,\n",
       " 'pytorch-lightning_version': '2.2.5',\n",
       " 'state_dict': OrderedDict([('message_passing.W_i.weight',\n",
       "               tensor([[ 5.5946e-02, -5.2682e-02,  4.2552e-02,  ...,  6.1952e-02,\n",
       "                        -5.2242e-02, -5.3086e-02],\n",
       "                       [-2.1555e-02, -1.1180e-01,  7.3735e-02,  ..., -7.5020e-02,\n",
       "                        -1.0554e-01, -7.9146e-02],\n",
       "                       [ 6.0962e-02,  1.0429e-01, -2.6556e-02,  ..., -4.2485e-02,\n",
       "                        -1.0189e-01, -5.6405e-02],\n",
       "                       ...,\n",
       "                       [ 4.1036e-02,  7.3391e-02, -8.3135e-02,  ..., -6.7459e-02,\n",
       "                        -7.9029e-05, -4.1186e-02],\n",
       "                       [-4.4437e-02,  3.6596e-02,  3.1334e-02,  ...,  3.8038e-02,\n",
       "                         3.1880e-02,  3.9304e-02],\n",
       "                       [ 1.1336e-01, -6.5759e-02,  6.2761e-02,  ...,  3.1353e-02,\n",
       "                        -9.2325e-02,  7.6437e-02]])),\n",
       "              ('message_passing.W_h.weight',\n",
       "               tensor([[-0.0672, -0.1449, -0.0389,  0.0232,  0.1303, -0.1689,  0.1422, -0.1086,\n",
       "                        -0.1493, -0.0998, -0.1499,  0.0186, -0.1352, -0.1227,  0.0752,  0.1375,\n",
       "                         0.0219, -0.1229, -0.0351,  0.1508],\n",
       "                       [ 0.0090,  0.1371, -0.0089, -0.0793,  0.0154,  0.1426, -0.1936, -0.0496,\n",
       "                        -0.0942,  0.2082, -0.1555, -0.1483,  0.1249, -0.1797,  0.2004,  0.0620,\n",
       "                         0.0431, -0.1125, -0.0081,  0.0285],\n",
       "                       [ 0.1047, -0.1974,  0.0183,  0.0677,  0.1457,  0.0179, -0.1114, -0.2145,\n",
       "                        -0.2140,  0.1280, -0.1339,  0.0499, -0.0119, -0.1180, -0.1923,  0.0781,\n",
       "                         0.0702, -0.0623, -0.0677,  0.1398],\n",
       "                       [ 0.0775, -0.0639,  0.1184,  0.0676,  0.1725, -0.1994, -0.1514,  0.0593,\n",
       "                         0.0773,  0.0077, -0.1668,  0.0928,  0.1774,  0.0052,  0.0246, -0.1307,\n",
       "                         0.0744, -0.0488,  0.1594,  0.1559],\n",
       "                       [-0.1809,  0.0443,  0.0004, -0.0733, -0.0661, -0.2156, -0.0721,  0.2127,\n",
       "                        -0.0581, -0.1100, -0.1859, -0.0463, -0.2130,  0.1398, -0.1643,  0.0752,\n",
       "                         0.1211,  0.2170, -0.1226, -0.0385],\n",
       "                       [ 0.1825,  0.1744,  0.1778, -0.1578, -0.0310,  0.2034, -0.0463,  0.0212,\n",
       "                         0.1693,  0.0017, -0.1995,  0.0764,  0.1077,  0.2115, -0.0027,  0.1020,\n",
       "                        -0.0707, -0.1390,  0.2166,  0.1985],\n",
       "                       [-0.1325,  0.1931,  0.1460, -0.2126,  0.2190, -0.2187, -0.0804, -0.0271,\n",
       "                        -0.0295,  0.0926,  0.0399,  0.1697, -0.1447, -0.0589,  0.0057,  0.1972,\n",
       "                        -0.0493, -0.0516, -0.1844, -0.1262],\n",
       "                       [-0.2146, -0.0052, -0.1278,  0.0828,  0.0245, -0.0261, -0.1314,  0.1392,\n",
       "                         0.0961,  0.1857, -0.0901,  0.0912,  0.1532, -0.1597, -0.0232,  0.1523,\n",
       "                         0.0134,  0.1275, -0.0322, -0.0422],\n",
       "                       [-0.2215, -0.2028, -0.2061, -0.0781, -0.0924,  0.0227,  0.0873, -0.0946,\n",
       "                         0.0485,  0.1636, -0.1659, -0.0597, -0.1308, -0.0867,  0.2077, -0.2039,\n",
       "                         0.1253,  0.2171, -0.0287, -0.0328],\n",
       "                       [ 0.2137, -0.1885,  0.0271,  0.0827,  0.0232,  0.0196,  0.0766, -0.2109,\n",
       "                         0.1198,  0.1132, -0.2027,  0.0312,  0.2076,  0.0634,  0.1890, -0.1153,\n",
       "                         0.0785, -0.2064, -0.0500,  0.0145],\n",
       "                       [-0.1446,  0.0773,  0.0232, -0.2141, -0.1960, -0.1419,  0.0420, -0.0766,\n",
       "                        -0.1982,  0.1290, -0.1355, -0.0733,  0.0231, -0.1182,  0.1316,  0.2022,\n",
       "                        -0.1967,  0.1026, -0.1875, -0.0676],\n",
       "                       [-0.1446, -0.0255,  0.0756, -0.1742, -0.0465, -0.1297, -0.1517, -0.1058,\n",
       "                        -0.0323, -0.1323,  0.0617,  0.0834, -0.1136,  0.2227, -0.0515,  0.1994,\n",
       "                         0.1656, -0.0721, -0.0154, -0.1823],\n",
       "                       [ 0.1613, -0.0060,  0.2218,  0.1644,  0.0085, -0.1258, -0.0715,  0.2231,\n",
       "                        -0.2086, -0.0722,  0.0998, -0.1001,  0.2020, -0.1211, -0.0312,  0.2140,\n",
       "                         0.1726, -0.0724,  0.1988,  0.0531],\n",
       "                       [ 0.2047,  0.1299, -0.2117,  0.1633, -0.0567,  0.0471,  0.0908, -0.1494,\n",
       "                        -0.1349,  0.1559, -0.0895,  0.0858, -0.0231,  0.1437, -0.1690,  0.2129,\n",
       "                         0.1213, -0.2157,  0.0087,  0.2209],\n",
       "                       [ 0.1275,  0.2122, -0.0727,  0.1459, -0.2043,  0.2211,  0.0889,  0.1317,\n",
       "                        -0.1875, -0.1941, -0.0565, -0.1578, -0.0065, -0.1675, -0.0179, -0.1054,\n",
       "                        -0.0754, -0.1094, -0.1908,  0.1513],\n",
       "                       [ 0.0464, -0.0430, -0.0444,  0.1576,  0.0923,  0.1182,  0.2001, -0.2215,\n",
       "                        -0.2179, -0.0760, -0.1130, -0.1228,  0.1203,  0.1375, -0.1972, -0.0439,\n",
       "                         0.1216, -0.2192,  0.1092, -0.0634],\n",
       "                       [ 0.0740,  0.0745,  0.1880,  0.0666,  0.0789, -0.1794,  0.1576, -0.1972,\n",
       "                        -0.0868,  0.0742, -0.1947, -0.0576, -0.0662, -0.0705, -0.0655, -0.0178,\n",
       "                        -0.0859, -0.1628,  0.1447,  0.1585],\n",
       "                       [-0.0091, -0.0153, -0.1431, -0.0146,  0.0352, -0.0030,  0.2159,  0.1474,\n",
       "                         0.2000,  0.0308,  0.0828, -0.1117,  0.0264, -0.0281,  0.0196,  0.0294,\n",
       "                        -0.1392, -0.0859,  0.0445, -0.0734],\n",
       "                       [-0.0890,  0.0399,  0.1966,  0.0242, -0.1250,  0.1626, -0.0473,  0.1533,\n",
       "                         0.0753,  0.1906,  0.0645,  0.1856, -0.0054, -0.0396,  0.2111,  0.1649,\n",
       "                        -0.1064, -0.1081, -0.1719, -0.1774],\n",
       "                       [-0.1272,  0.1177,  0.1409, -0.1318,  0.1097,  0.2227,  0.1596, -0.1071,\n",
       "                        -0.0320, -0.1068,  0.1109,  0.1512,  0.0844, -0.0207, -0.0722,  0.0103,\n",
       "                         0.1598,  0.1581,  0.1367,  0.1614]])),\n",
       "              ('message_passing.W_o.weight',\n",
       "               tensor([[ 0.0895,  0.0066, -0.0215,  ..., -0.0045,  0.0713,  0.0703],\n",
       "                       [ 0.0804, -0.0070, -0.0542,  ..., -0.0215,  0.0014,  0.0736],\n",
       "                       [ 0.0421, -0.0774, -0.0570,  ..., -0.0540,  0.0923, -0.0051],\n",
       "                       ...,\n",
       "                       [ 0.0336,  0.0877, -0.0655,  ..., -0.1060, -0.0631, -0.0335],\n",
       "                       [ 0.0123, -0.0024, -0.0562,  ..., -0.0046,  0.0100,  0.1059],\n",
       "                       [-0.0724, -0.0915,  0.1017,  ..., -0.0956,  0.0332,  0.0139]])),\n",
       "              ('message_passing.W_o.bias',\n",
       "               tensor([-0.0688, -0.0781, -0.0625,  0.0713, -0.0739,  0.0012, -0.0323, -0.0468,\n",
       "                        0.0140, -0.0204,  0.0035, -0.0358,  0.0632, -0.0971, -0.0339, -0.0552,\n",
       "                        0.1015,  0.0296, -0.0666,  0.0218])),\n",
       "              ('bn.weight',\n",
       "               tensor([0.9994, 0.9994, 1.0007, 1.0006, 1.0000, 1.0006, 1.0006, 1.0006, 0.9994,\n",
       "                       1.0006, 0.9994, 0.9994, 1.0006, 1.0006, 0.9994, 1.0000, 0.9994, 0.9995,\n",
       "                       0.9994, 0.9994])),\n",
       "              ('bn.bias',\n",
       "               tensor([-0.0006,  0.0006,  0.0006, -0.0007, -0.0007,  0.0007,  0.0007,  0.0007,\n",
       "                        0.0006,  0.0007, -0.0006,  0.0006, -0.0006,  0.0007,  0.0006, -0.0006,\n",
       "                       -0.0006, -0.0006,  0.0006,  0.0006])),\n",
       "              ('bn.running_mean',\n",
       "               tensor([0.0058, 0.0044, 0.0010, 0.0221, 0.0000, 0.0013, 0.0253, 0.0077, 0.0379,\n",
       "                       0.0004, 0.0029, 0.0175, 0.0259, 0.0035, 0.0147, 0.0000, 0.0130, 0.0002,\n",
       "                       0.0019, 0.0376])),\n",
       "              ('bn.running_var',\n",
       "               tensor([0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                       0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100, 0.8100,\n",
       "                       0.8100, 0.8100])),\n",
       "              ('bn.num_batches_tracked', tensor(2)),\n",
       "              ('predictor.criterion.task_weights', tensor([[1.]])),\n",
       "              ('reduce_X_d.linear_layer.weight',\n",
       "               tensor([[-0.0002,  0.0036, -0.0158,  ..., -0.0039, -0.0158, -0.0141],\n",
       "                       [-0.0248, -0.0013, -0.0254,  ..., -0.0207, -0.0007, -0.0063],\n",
       "                       [-0.0115, -0.0139,  0.0229,  ...,  0.0172, -0.0031, -0.0092],\n",
       "                       ...,\n",
       "                       [-0.0097,  0.0128, -0.0256,  ..., -0.0149, -0.0151, -0.0075],\n",
       "                       [ 0.0092, -0.0020, -0.0032,  ...,  0.0068,  0.0183, -0.0233],\n",
       "                       [ 0.0140,  0.0250,  0.0234,  ..., -0.0096, -0.0195, -0.0224]])),\n",
       "              ('reduce_X_d.linear_layer.bias',\n",
       "               tensor([ 0.0155,  0.0112, -0.0060,  0.0168, -0.0273, -0.0084, -0.0133,  0.0201,\n",
       "                       -0.0011, -0.0166,  0.0104, -0.0063,  0.0144, -0.0029, -0.0098, -0.0139,\n",
       "                        0.0163, -0.0152,  0.0163,  0.0201]))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 2},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 2,\n",
       "     'completed': 2,\n",
       "     'started': 2,\n",
       "     'processed': 2},\n",
       "    'current': {'ready': 1, 'completed': 1, 'started': 1, 'processed': 1},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 2, 'completed': 2},\n",
       "    'current': {'ready': 1, 'completed': 1}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 2,\n",
       "       'completed': 2},\n",
       "      'current': {'ready': 1, 'completed': 1}},\n",
       "     'zero_grad': {'total': {'ready': 2, 'completed': 2, 'started': 2},\n",
       "      'current': {'ready': 1, 'completed': 1, 'started': 1}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False},\n",
       "   'epoch_progress': {'total': {'ready': 2,\n",
       "     'completed': 1,\n",
       "     'started': 2,\n",
       "     'processed': 2},\n",
       "    'current': {'ready': 2, 'completed': 1, 'started': 2, 'processed': 2}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/projects/p30041/spn1560/hiec/artifacts/model_evals/gnn/78_hp_idx_split_1_of_2/version_0/checkpoints/epoch=1-step=2.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/projects/p30041/spn1560/hiec/artifacts/model_evals/gnn/78_hp_idx_split_1_of_2/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              -6.5869e-05,  0.0000e+00],\n",
       "             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "               0.0000e+00,  1.0554e-02],\n",
       "             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "               5.0179e-03,  2.8537e-02],\n",
       "             ...,\n",
       "             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              -2.1510e-03, -8.3718e-03],\n",
       "             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.2017e-02,\n",
       "              -3.5875e-02, -1.2666e-02],\n",
       "             [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.5850e-02,\n",
       "              -3.4541e-02, -1.1742e-02]]),\n",
       "     'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 2.5556e-10,\n",
       "              0.0000e+00],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "              7.6375e-06],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 2.0706e-06,\n",
       "              4.9706e-05],\n",
       "             ...,\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 3.1779e-07,\n",
       "              4.5149e-06],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.6679e-05, 1.1103e-04,\n",
       "              2.4839e-05],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0407e-04, 9.8081e-05,\n",
       "              2.0971e-05]])},\n",
       "    2: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0028,  0.0121,  0.0048],\n",
       "             [ 0.0000,  0.0000,  0.0000,  ..., -0.0003,  0.0008,  0.0014],\n",
       "             [ 0.0000,  0.0000,  0.0000,  ...,  0.0002, -0.0054, -0.0080],\n",
       "             ...,\n",
       "             [ 0.0000,  0.0000,  0.0000,  ..., -0.0004, -0.0016, -0.0009],\n",
       "             [ 0.0000,  0.0000,  0.0000,  ...,  0.0044,  0.0272,  0.0043],\n",
       "             [ 0.0000,  0.0000,  0.0000,  ..., -0.0004,  0.0084,  0.0042]]),\n",
       "     'exp_avg_sq': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.8128e-07, 1.1945e-05,\n",
       "              2.1271e-06],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.9307e-09, 3.1426e-08,\n",
       "              1.2211e-07],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.3563e-09, 1.8063e-06,\n",
       "              4.1496e-06],\n",
       "             ...,\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.7416e-09, 1.4788e-07,\n",
       "              4.5319e-08],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2921e-06, 4.8859e-05,\n",
       "              1.1858e-06],\n",
       "             [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.2827e-09, 4.3170e-06,\n",
       "              1.0166e-06]])},\n",
       "    3: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([ 5.7290e-02,  4.6631e-03, -3.2860e-02,  7.2734e-04,  0.0000e+00,\n",
       "             -4.7445e-02, -1.6006e-02, -4.1655e-02,  5.8985e-04, -5.1992e-02,\n",
       "              4.9482e-02, -8.5230e-03, -1.2594e-06, -4.1321e-02,  4.6226e-02,\n",
       "              0.0000e+00, -3.3544e-03, -1.1400e-02,  6.4140e-02,  9.6887e-03]),\n",
       "     'exp_avg_sq': tensor([2.2706e-04, 1.2203e-06, 6.3064e-05, 5.1109e-07, 0.0000e+00, 1.2449e-04,\n",
       "             1.4459e-05, 1.0456e-04, 6.9740e-08, 1.5817e-04, 1.6092e-04, 8.6955e-06,\n",
       "             1.3893e-13, 1.2179e-04, 1.5181e-04, 0.0000e+00, 1.3295e-06, 8.3545e-06,\n",
       "             2.7266e-04, 5.6313e-06])},\n",
       "    4: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([ 1.1669e-02,  1.1427e-03, -1.2480e-03, -9.6067e-03,  0.0000e+00,\n",
       "             -2.3038e-03, -1.1837e-02, -8.6684e-03,  3.9857e-03, -3.7161e-03,\n",
       "              7.0925e-03,  8.9274e-03, -8.0843e-04, -3.7083e-04,  1.1661e-02,\n",
       "              0.0000e+00,  1.8388e-04, -3.3810e-05,  4.4533e-03,  5.6340e-03]),\n",
       "     'exp_avg_sq': tensor([1.0506e-05, 8.5448e-08, 8.6168e-08, 6.0774e-06, 0.0000e+00, 3.7653e-07,\n",
       "             8.6788e-06, 4.7661e-06, 1.0242e-06, 7.9546e-07, 3.9762e-06, 5.4891e-06,\n",
       "             5.9209e-08, 1.5664e-07, 9.3873e-06, 0.0000e+00, 1.6555e-08, 2.9717e-10,\n",
       "             1.3297e-06, 3.2087e-06])},\n",
       "    5: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([ 0.0125, -0.0037, -0.0022,  0.0118,  0.0143, -0.0165, -0.0112, -0.0076,\n",
       "             -0.0086, -0.0133,  0.0089, -0.0092,  0.0121, -0.0158, -0.0096,  0.0159,\n",
       "              0.0014,  0.0007, -0.0124, -0.0133]),\n",
       "     'exp_avg_sq': tensor([8.8003e-06, 7.5045e-07, 3.4315e-07, 7.6704e-06, 1.1290e-05, 1.4950e-05,\n",
       "             6.9793e-06, 3.1736e-06, 4.2708e-06, 9.7081e-06, 4.4209e-06, 4.8574e-06,\n",
       "             8.2295e-06, 1.3779e-05, 5.2009e-06, 1.4077e-05, 1.3168e-07, 1.9946e-07,\n",
       "             8.6715e-06, 9.8490e-06])},\n",
       "    6: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([[ 2.8447e-03, -4.2360e-03,  3.7134e-03,  ..., -2.6474e-03,\n",
       "              -2.8913e-04, -1.9743e-03],\n",
       "             [ 2.2461e-03, -2.9215e-03,  3.1066e-03,  ..., -2.2513e-03,\n",
       "              -7.1279e-04, -1.6723e-03],\n",
       "             [ 7.6110e-04, -2.4868e-03,  4.3969e-04,  ..., -1.9591e-04,\n",
       "               1.4683e-03, -1.7258e-04],\n",
       "             ...,\n",
       "             [-1.2180e-04, -3.0978e-04, -3.5658e-04,  ...,  2.9739e-04,\n",
       "               5.7037e-04,  2.0938e-04],\n",
       "             [-5.9319e-04,  2.2026e-03, -2.4074e-04,  ...,  5.6101e-05,\n",
       "              -1.4410e-03,  7.2420e-05],\n",
       "             [-2.9772e-03,  5.2400e-03, -3.5658e-03,  ...,  2.4707e-03,\n",
       "              -6.1033e-04,  1.8685e-03]]),\n",
       "     'exp_avg_sq': tensor([[4.6773e-07, 1.5227e-06, 7.6340e-07,  ..., 3.8759e-07, 2.7086e-07,\n",
       "              2.1796e-07],\n",
       "             [2.9166e-07, 7.7505e-07, 5.3512e-07,  ..., 2.7996e-07, 1.7065e-07,\n",
       "              1.5691e-07],\n",
       "             [3.2242e-08, 3.7599e-07, 1.1800e-08,  ..., 3.6955e-09, 1.4898e-07,\n",
       "              1.8984e-09],\n",
       "             ...,\n",
       "             [8.2190e-10, 5.3036e-09, 7.0218e-09,  ..., 4.8848e-09, 1.7968e-08,\n",
       "              2.4339e-09],\n",
       "             [2.0912e-08, 3.1147e-07, 3.2085e-09,  ..., 4.4320e-10, 1.4067e-07,\n",
       "              2.9279e-10],\n",
       "             [5.1213e-07, 2.1241e-06, 7.0338e-07,  ..., 3.3820e-07, 3.3668e-07,\n",
       "              1.9490e-07]])},\n",
       "    7: {'step': tensor(2.),\n",
       "     'exp_avg': tensor([-2.2629e-02, -1.6115e-02, -1.1674e-02,  2.9423e-02,  1.0363e-05,\n",
       "             -4.8497e-03, -3.0978e-02, -1.7052e-02,  2.5936e-02, -1.3039e-02,\n",
       "             -2.3814e-02,  2.4988e-02, -5.5170e-05, -7.0766e-03,  3.1433e-02,\n",
       "              1.0363e-05,  1.7106e-02, -1.0787e-03,  1.0211e-02,  2.7062e-02]),\n",
       "     'exp_avg_sq': tensor([4.0252e-05, 2.1280e-05, 8.2165e-06, 6.1635e-05, 1.0740e-11, 1.7922e-06,\n",
       "             6.4265e-05, 2.2075e-05, 3.8558e-05, 1.0284e-05, 4.1858e-05, 4.0685e-05,\n",
       "             3.2758e-07, 5.3729e-06, 6.5040e-05, 1.0740e-11, 2.2390e-05, 6.4568e-08,\n",
       "             6.6752e-06, 5.3999e-05])}},\n",
       "   'param_groups': [{'lr': 0.0001,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'initial_lr': 0.0001,\n",
       "     'params': [0, 1, 2, 3, 4, 5, 6, 7]}]}],\n",
       " 'lr_schedulers': [{'num_lrs': 1,\n",
       "   'final_lrs': array([0.0001]),\n",
       "   'current_step': 3,\n",
       "   'lrs': array([0.0001]),\n",
       "   'scheds': array([[0.0001 , 0.00055]]),\n",
       "   'base_lrs': [0.0001],\n",
       "   'last_epoch': -1,\n",
       "   'verbose': False,\n",
       "   '_step_count': 0}],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'batch_norm': True,\n",
       "  'metrics': None,\n",
       "  'warmup_epochs': 2,\n",
       "  'init_lr': 0.0001,\n",
       "  'max_lr': 0.001,\n",
       "  'final_lr': 0.0001,\n",
       "  'X_d_transform': None,\n",
       "  'message_passing': \"V_d_transform\":   None\n",
       "  \"activation\":      relu\n",
       "  \"bias\":            False\n",
       "  \"cls\":             <class 'chemprop.nn.message_passing.base.BondMessagePassing'>\n",
       "  \"d_e\":             7\n",
       "  \"d_h\":             20\n",
       "  \"d_v\":             67\n",
       "  \"d_vd\":            None\n",
       "  \"depth\":           1\n",
       "  \"dropout\":         0.0\n",
       "  \"graph_transform\": None\n",
       "  \"undirected\":      False,\n",
       "  'agg': {'dim': 0, 'cls': chemprop.nn.agg.MeanAggregation},\n",
       "  'predictor': ,\n",
       "  'reduce_X_d': \"cls\":   <class 'src.nn.LinDimRed'>\n",
       "  \"d_in\":  1280\n",
       "  \"d_out\": 20}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.cross_validation import BatchGridSearch, BatchScript, HyperHyperParams\n",
    "from dataclasses import fields\n",
    "from math import isnan\n",
    "\n",
    "def fix_ints(hp_dict):\n",
    "    to_fix = [\n",
    "        'encoder_depth',\n",
    "        'embed_dim',\n",
    "        'seed',\n",
    "        'n_epochs',\n",
    "        'd_h_encoder',\n",
    "        'n_splits',\n",
    "        'neg_multiple',\n",
    "    ]\n",
    "    \n",
    "    for elt in to_fix:\n",
    "        if elt not in hp_dict:\n",
    "            continue\n",
    "        elif isnan(hp_dict[elt]):\n",
    "            continue\n",
    "        else:\n",
    "            hp_dict[elt]  = int(hp_dict[elt])\n",
    "    \n",
    "    return hp_dict\n",
    "\n",
    "# Args\n",
    "allocation = 'b1039'\n",
    "partition = 'b1039'\n",
    "mem = '12G' # 12G\n",
    "time = '12' # Hours 12\n",
    "fit_script = 'two_channel_fit.py'\n",
    "batch_script = BatchScript(allocation=allocation, partition=partition, mem=mem, time=time, script=fit_script)\n",
    "res_dir = \"/projects/p30041/spn1560/hiec/artifacts/model_evals/gnn\"\n",
    "\n",
    "# Old hp_idxs : total epochs to train up to\n",
    "hp_idx_epochs = {\n",
    "    # 29:50,\n",
    "    # 28:50,\n",
    "    # 45:50,\n",
    "    8:50,\n",
    "    68:50,\n",
    "    # 46:50,\n",
    "    # 47:50,\n",
    "}\n",
    "\n",
    "experiments = pd.read_csv(f\"{res_dir}/experiments.csv\", sep='\\t', index_col=0)\n",
    "to_resume = experiments.loc[hp_idx_epochs.keys()]\n",
    "by = [field.name for field in fields(HyperHyperParams)]\n",
    "gb = to_resume.groupby(by=by)\n",
    "other_columns = [col for col in experiments.columns if col not in by]\n",
    "\n",
    "# Chunk hps into groups w/ shared hyper hps\n",
    "hhp_args = []\n",
    "hps = []\n",
    "chkpt_idxs = [] # Where to load model ckpt from\n",
    "for hhp_vals, group in gb:\n",
    "    hhp_args.append({k: v for k,v in zip(by, hhp_vals)})\n",
    "    hp_chunk = []\n",
    "    chckpt_chunk = []\n",
    "    for hp_idx, row in group.iterrows():\n",
    "        tmp = {col : row[col] for col in other_columns}\n",
    "        tmp['n_epochs'] = hp_idx_epochs[hp_idx] # Resumed fit should have all same hps EXCEPT n_epochs\n",
    "        hp_chunk.append(tmp)\n",
    "        chckpt_chunk.append(hp_idx)\n",
    "\n",
    "    chkpt_idxs.append(chckpt_chunk)\n",
    "    hps.append(hp_chunk)\n",
    "\n",
    "# # Run bsg\n",
    "# for hhp, hp, chkpt in zip(hhp_args, hps, chkpt_idxs):\n",
    "#     hp = [fix_ints(elt) for elt in hp]\n",
    "#     hhp = fix_ints(hhp)\n",
    "#     hhps = HyperHyperParams(**hhp)\n",
    "#     gs = BatchGridSearch(hhps, res_dir)\n",
    "#     gs.resume(hp, batch_script, chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = hps[0][0]['message_passing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import lightning as L\n",
    "\n",
    "# define any number of nn.Modules (or use your current ones)\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, _ = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = nn.functional.mse_loss(x_hat, x)\n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "\n",
    "# init the autoencoder\n",
    "autoencoder = LitAutoEncoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /home/spn1560/hiec/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 53905870.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/spn1560/hiec/MNIST/raw/train-images-idx3-ubyte.gz to /home/spn1560/hiec/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /home/spn1560/hiec/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1434696.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/spn1560/hiec/MNIST/raw/train-labels-idx1-ubyte.gz to /home/spn1560/hiec/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /home/spn1560/hiec/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 12994129.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/spn1560/hiec/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/spn1560/hiec/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /home/spn1560/hiec/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1988988.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/spn1560/hiec/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/spn1560/hiec/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup data\n",
    "dataset = MNIST(os.getcwd(), download=True, transform=ToTensor())\n",
    "train_loader = utils.data.DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spn1560/.conda/envs/hiec/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/spn1560/.conda/envs/hiec/lib/python3.11/site-p ...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/spn1560/hiec/lightning_logs\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 50.4 K\n",
      "1 | decoder | Sequential | 51.2 K\n",
      "---------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/home/spn1560/.conda/envs/hiec/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=51` in the `DataLoader` to improve performance.\n",
      "`Trainer.fit` stopped: `max_epochs=0` reached.\n"
     ]
    }
   ],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(limit_train_batches=100, max_epochs=0)\n",
    "trainer.fit(model=autoencoder, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hiec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
